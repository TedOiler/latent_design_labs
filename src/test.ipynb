{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.sos import ScalarOnScalarModel\n",
    "# from optimizers.nbdo import NBDO\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from models.sof import ScalarOnFunctionModel\n",
    "# import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SoS\n",
    "# model = ScalarOnScalarModel(Kx=3, criterion=\"A\", order=2)\n",
    "# nbdo = NBDO(model=model, latent_dim=10, seed=42)\n",
    "# nbdo.compute_train_set(num_designs=1_000, runs=25)\n",
    "# nbdo.fit(epochs=1_000, patience=100, batch_size=256)\n",
    "# crit, design = nbdo.optimize(n_calls=30)\n",
    "# np.round(crit,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SoF\n",
    "# xB, bB = BSplineBasis(0,4), BSplineBasis(0,2)\n",
    "# model = ScalarOnFunctionModel([(xB,bB)], criterion=\"D\", intercept=True)\n",
    "# nbdo = NBDO(model=model, latent_dim=2, seed=42, verbose=False)\n",
    "# nbdo.compute_train_set(num_designs=1_000, runs=12)\n",
    "# nbdo.fit(epochs=10, patience=5, batch_size=256)\n",
    "# crit, design = nbdo.optimize(n_calls=5)\n",
    "# crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from diagnostics import (\n",
    "#     info_matrix, eigen_spectrum, condition_number,\n",
    "#     leverage_diag, prediction_variance,\n",
    "# )\n",
    "\n",
    "# M = info_matrix(model, design)\n",
    "# eigvals, _ = eigen_spectrum(M)\n",
    "# kappa = condition_number(M)\n",
    "# print(f\"p = {M.shape[0]}, λ_min = {eigvals[-1]:.3e}, λ_max = {eigvals[0]:.3e}, κ2 = {kappa:.2e}\")\n",
    "\n",
    "# h = leverage_diag(model, design)\n",
    "# print(f\"leverage stats: min={h.min():.3f}, max={h.max():.3f}, mean={h.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = 10, λ_min = 3.458e+00, λ_max = 5.728e+01, κ2 = 1.66e+01\n",
    "# leverage stats: min=0.179, max=0.748, mean=0.400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # quick smoke test\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from models.fof import FunctionOnFunctionModel\n",
    "# from optimizers.nbdo import NBDO\n",
    "\n",
    "# def B(K, deg):\n",
    "#     return BSplineBasis(degree=deg, total_knots_num=max(2, K - deg + 1))\n",
    "\n",
    "# bx, bb = B(5,2), B(6,2)\n",
    "# model = FunctionOnFunctionModel([(bx, bb)], criterion=\"A\", intercept=True)\n",
    "# opt = NBDO(model=model, latent_dim=4, seed=0)\n",
    "# opt.compute_train_set(num_designs=1_000, runs=12)\n",
    "# opt.fit(epochs=1_000, patience=100, batch_size=256)       # should converge & print losses\n",
    "# report, design = opt.optimize(n_calls=5, n_random_starts=3)\n",
    "# print(\"ok ✅\", report, design.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from models.sof import ScalarOnFunctionModel\n",
    "# from models.fof import FunctionOnFunctionModel\n",
    "\n",
    "# def B(K, deg):\n",
    "#     total_knots_num = max(2, K - deg + 1)\n",
    "#     return BSplineBasis(degree=deg, total_knots_num=total_knots_num)\n",
    "\n",
    "# # Two predictors, different dims\n",
    "# bx1, bb1 = B(5,2), B(6,2)\n",
    "# bx2, bb2 = B(4,3), B(3,3)\n",
    "# pairs = [(bx1, bb1), (bx2, bb2)]\n",
    "\n",
    "# runs = 14\n",
    "\n",
    "# fof = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=True)\n",
    "# sof = ScalarOnFunctionModel(pairs, criterion=\"A\", intercept=True)\n",
    "\n",
    "# # Build Γ by concatenating per-predictor blocks\n",
    "# rng = np.random.default_rng(0)\n",
    "# Gamma = np.hstack([\n",
    "#     rng.normal(size=(runs, fof.Kx_list[0])),\n",
    "#     rng.normal(size=(runs, fof.Kx_list[1])),\n",
    "# ])\n",
    "\n",
    "# # Block-diag sanity: each slice maps correctly\n",
    "# Phi = Gamma @ fof.J_np\n",
    "# for xs, bs in zip(fof.x_slices, fof.b_slices):\n",
    "#     Ji = fof.J_np[xs, :][:, bs]\n",
    "#     assert np.allclose(Gamma[:, xs] @ Ji, Phi[:, bs], atol=1e-12)\n",
    "\n",
    "# # Shapes and parity\n",
    "# Zf, Zs = fof.model_matrix(Gamma), sof.model_matrix(Gamma)\n",
    "# Mf, Ms = fof.information_matrix(Zf), sof.information_matrix(Zs)\n",
    "# print(\"Z shapes:\", Zf.shape, Zs.shape)\n",
    "# print(\"M shapes:\", Mf.shape, Ms.shape)\n",
    "\n",
    "# vf, vs = fof.objective_num(Gamma), sof.objective_num(Gamma)\n",
    "# print(\"A-opt FoF vs SoF:\", vf, vs)\n",
    "# assert np.allclose(vf, vs, rtol=1e-10, atol=1e-10)\n",
    "\n",
    "# print(\"Multi-predictor behavior matches SoF ✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Scalar-on-Function parity baseline ---\n",
    "\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from models.sof import ScalarOnFunctionModel\n",
    "\n",
    "# # reproducibility\n",
    "# rng = np.random.default_rng(12345)\n",
    "# tf.keras.utils.set_random_seed(12345)\n",
    "\n",
    "# def B(K: int, degree: int) -> BSplineBasis:\n",
    "#     \"\"\"\n",
    "#     Your BSplineBasis signature: (degree, total_knots_num)\n",
    "#     Relation: K = degree + total_knots_num - 1  -> total_knots_num = K - degree + 1\n",
    "#     \"\"\"\n",
    "#     total_knots_num = max(2, K - degree + 1)\n",
    "#     return BSplineBasis(degree=degree, total_knots_num=total_knots_num)\n",
    "\n",
    "# # --- common design setup (multi-predictor) ---\n",
    "# deg1, deg2 = 2, 2\n",
    "# Kx1, Kb1 = 5, 6    # predictor 1: design basis size, beta(s,·) s-basis size\n",
    "# Kx2, Kb2 = 4, 3    # predictor 2: design basis size, beta(s,·) s-basis size\n",
    "\n",
    "# bx1, bb1 = B(Kx1, deg1), B(Kb1, deg1)\n",
    "# bx2, bb2 = B(Kx2, deg2), B(Kb2, deg2)\n",
    "# pairs = [(bx1, bb1), (bx2, bb2)]\n",
    "\n",
    "# intercept = True\n",
    "# Kb_total = Kb1 + Kb2\n",
    "# p = Kb_total + (1 if intercept else 0)\n",
    "\n",
    "# runs = 14  # ensure runs > p for a well-conditioned M\n",
    "\n",
    "# # --- build model(s) ---\n",
    "# sof_A = ScalarOnFunctionModel(pairs, criterion=\"A\", intercept=intercept, dtype=tf.float64)\n",
    "# sof_D = ScalarOnFunctionModel(pairs, criterion=\"D\", intercept=intercept, dtype=tf.float64)\n",
    "\n",
    "# # --- design coefficients Γ: (runs, Kx_total) ---\n",
    "# Gamma = rng.normal(size=(runs, sof_A.Kx))\n",
    "\n",
    "# # --- shapes & quick info ---\n",
    "# print(\"=== Scalar-on-Function (baseline) ===\")\n",
    "# print(f\"Kx_list={sof_A.Kx_list}, sum={sof_A.Kx} | Kb_list={sof_A.Kb_list}, sum={sof_A.Kb}\")\n",
    "# print(f\"p={sof_A.p} (should equal {p}), runs={runs}\")\n",
    "# print(\"J shape:\", sof_A.J_np.shape)\n",
    "\n",
    "# Z = sof_A.model_matrix(Gamma)\n",
    "# M = sof_A.information_matrix(Z)\n",
    "# print(\"Z shape:\", Z.shape, \"| M shape:\", M.shape)\n",
    "\n",
    "# # --- criteria values ---\n",
    "# A_val = sof_A.objective_num(Gamma)\n",
    "# D_val = sof_D.objective_num(Gamma)\n",
    "\n",
    "# print(\"\\nResults to copy:\")\n",
    "# print(f\"A-opt (trace(M^{-1})) loss: {A_val:.12f}\")\n",
    "# print(f\"D-opt (-logdet M) loss:     {D_val:.12f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Function-on-Function parity check (should match SoF numbers) ---\n",
    "\n",
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from models.fof import FunctionOnFunctionModel\n",
    "\n",
    "# # reproducibility (same seeds as in Cell 1)\n",
    "# rng = np.random.default_rng(12345)\n",
    "# tf.keras.utils.set_random_seed(12345)\n",
    "\n",
    "# def B(K: int, degree: int) -> BSplineBasis:\n",
    "#     total_knots_num = max(2, K - degree + 1)\n",
    "#     return BSplineBasis(degree=degree, total_knots_num=total_knots_num)\n",
    "\n",
    "# # --- same common design setup (multi-predictor) ---\n",
    "# deg1, deg2 = 2, 2\n",
    "# Kx1, Kb1 = 5, 6\n",
    "# Kx2, Kb2 = 4, 3\n",
    "\n",
    "# bx1, bb1 = B(Kx1, deg1), B(Kb1, deg1)\n",
    "# bx2, bb2 = B(Kx2, deg2), B(Kb2, deg2)\n",
    "# pairs = [(bx1, bb1), (bx2, bb2)]\n",
    "\n",
    "# intercept = True\n",
    "# Kb_total = Kb1 + Kb2\n",
    "# p = Kb_total + (1 if intercept else 0)\n",
    "\n",
    "# runs = 14  # same as Cell 1\n",
    "\n",
    "# # --- build model(s) ---\n",
    "# fof_A = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=intercept, dtype=tf.float64, response_basis=None)\n",
    "# fof_D = FunctionOnFunctionModel(pairs, criterion=\"D\", intercept=intercept, dtype=tf.float64, response_basis=None)\n",
    "\n",
    "# # --- design coefficients Γ: (runs, Kx_total) -- same RNG/state as Cell 1 ---\n",
    "# Gamma = rng.normal(size=(runs, fof_A.Kx))\n",
    "\n",
    "# # --- shapes & quick info ---\n",
    "# print(\"=== Function-on-Function (to match SoF) ===\")\n",
    "# print(f\"Kx_list={fof_A.Kx_list}, sum={fof_A.Kx} | Kb_list={fof_A.Kb_list}, sum={fof_A.Kb}\")\n",
    "# print(f\"p={fof_A.p} (should equal {p}), runs={runs}\")\n",
    "# print(\"J shape:\", fof_A.J_np.shape)\n",
    "\n",
    "# Z = fof_A.model_matrix(Gamma)\n",
    "# M = fof_A.information_matrix(Z)\n",
    "# print(\"Z shape:\", Z.shape, \"| M shape:\", M.shape)\n",
    "\n",
    "# # --- criteria values (should match those you copied from Cell 1) ---\n",
    "# A_val = fof_A.objective_num(Gamma)\n",
    "# D_val = fof_D.objective_num(Gamma)\n",
    "\n",
    "# print(\"\\nCompare to your SoF notes:\")\n",
    "# print(f\"A-opt (trace(M^{-1})) loss: {A_val:.12f}\")\n",
    "# print(f\"D-opt (-logdet M) loss:     {D_val:.12f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from models.sof import ScalarOnFunctionModel\n",
    "# from inner_products.penalty import PenaltyBuilder\n",
    "\n",
    "# # --- Build a simple 1-factor setup ---\n",
    "# xB = BSplineBasis(degree=3, total_knots_num=12)  # input basis (Kx)\n",
    "# bB = BSplineBasis(degree=3, total_knots_num=12)  # parameter basis (Kb)\n",
    "# basis_pairs = [(xB, bB), (xB, bB)]\n",
    "\n",
    "# # --- PenaltyBuilder sanity ---\n",
    "# pb = PenaltyBuilder([bB], quad_points=256, diff_h=1e-4)\n",
    "# R0 = pb.build()\n",
    "# print(\"R0 shape:\", R0.shape)              # expect (Kb, Kb)\n",
    "# evals = np.linalg.eigvalsh((R0 + R0.T) * 0.5)\n",
    "# print(\"R0 min eigenvalue:\", evals.min())  # should be >= -1e-10 (numeric noise)\n",
    "\n",
    "# # --- Build two SoF models (no penalty vs. λ>0) ---\n",
    "# m0 = ScalarOnFunctionModel(basis_pairs, criterion=\"D\", intercept=True, lambda_penalty=None)\n",
    "# m1 = ScalarOnFunctionModel(basis_pairs, criterion=\"D\", intercept=True, lambda_penalty=1.0)\n",
    "\n",
    "# runs = 8\n",
    "# Gamma = np.random.uniform(-1, 1, size=(runs, m0.Kx)).astype(np.float64)\n",
    "\n",
    "# # Z and M for the base (no-penalty) model\n",
    "# Z0 = m0.model_matrix(tf.constant(Gamma))\n",
    "# M0 = m0.information_matrix(Z0).numpy()\n",
    "\n",
    "# # Check that m1 builds R̃ (p x p) with zero top-left for intercept\n",
    "# R_tilde = m1.R.numpy()\n",
    "# print(\"R̃ shape:\", R_tilde.shape, \"p=\", m1.p)\n",
    "# print(\"Intercept penalty entry (should be 0):\", R_tilde[0, 0])\n",
    "\n",
    "# # Verify that regularization equals M + λR̃ (regularization is applied only inside objective/report)\n",
    "# M_reg_expected = M0 + 1.0 * R_tilde\n",
    "# M_reg_actual = m1._regularize_information(tf.constant(M0)).numpy()\n",
    "# print(\"Regularization close:\", np.allclose(M_reg_expected, M_reg_actual, atol=1e-10))\n",
    "\n",
    "# # Quick criterion sanity (no need for equality, just that λ changes it smoothly)\n",
    "# loss0 = float(m0.objective(tf.constant(Gamma)).numpy().reshape(()))\n",
    "# loss1 = float(m1.objective(tf.constant(Gamma)).numpy().reshape(()))\n",
    "# print(\"Loss (λ=None):\", loss0)\n",
    "# print(\"Loss (λ=1.0):\", loss1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from bases.polynomial import PolynomialBasis\n",
    "# from inner_products.penalty import PenaltyBuilder\n",
    "\n",
    "# # Analytic R0 for monomial basis {1, t, ..., t^d}\n",
    "# def analytic_R_poly(degree: int) -> np.ndarray:\n",
    "#     K = degree + 1\n",
    "#     R = np.zeros((K, K), dtype=float)\n",
    "#     for i in range(2, K):\n",
    "#         for j in range(2, K):\n",
    "#             R[i, j] = (i * (i - 1) * j * (j - 1)) / (i + j - 3)\n",
    "#     return R\n",
    "\n",
    "# # Build numeric R0\n",
    "# pB = PolynomialBasis(degree=3)\n",
    "# pb = PenaltyBuilder([pB], quad_points=256, diff_h=1e-4)\n",
    "# R0_num = pb.build()\n",
    "\n",
    "# R0_ref = analytic_R_poly(3)\n",
    "\n",
    "# print(\"Numeric R0:\\n\", np.round(R0_num, 6))\n",
    "# print(\"Analytic R0:\\n\", R0_ref)\n",
    "# print(\"Abs diff:\\n\", np.round(np.abs(R0_num - R0_ref), 8))\n",
    "# print(\"Max abs diff:\", float(np.max(np.abs(R0_num - R0_ref))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bases.polynomial import PolynomialBasis\n",
    "# from models.sof import ScalarOnFunctionModel\n",
    "# import numpy as np, tensorflow as tf\n",
    "\n",
    "# xB = PolynomialBasis(3)   # just to get a quick Kx\n",
    "# bB = PolynomialBasis(3)\n",
    "# m0 = ScalarOnFunctionModel([(xB,bB)], criterion=\"D\", intercept=True)            # no penalty\n",
    "# m1 = ScalarOnFunctionModel([(xB,bB)], criterion=\"D\", intercept=True, lambda_penalty=0.1)\n",
    "\n",
    "# runs = 6\n",
    "# Gamma = np.random.uniform(-1,1,(runs,m0.Kx)).astype(np.float64)\n",
    "# print(\"penalty active?\", m1.R is not None, \"R̃ shape:\", None if m1.R is None else m1.R.shape)\n",
    "# print(\"loss (λ=None) vs (λ=0.1):\", float(m0.objective(Gamma)), float(m1.objective(Gamma)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Smoke test: Scalar-on-Function + NBDO (no penalty) ---\n",
    "# import os, numpy as np, tensorflow as tf\n",
    "\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from models.sof import ScalarOnFunctionModel\n",
    "# from optimizers.nbdo import NBDO\n",
    "\n",
    "# # Reproducibility\n",
    "# SEED = 42\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "# # Bases (1 factor for speed; feel free to add more)\n",
    "# xB = BSplineBasis(degree=3, total_knots_num=12)   # input basis\n",
    "# bB = BSplineBasis(degree=3, total_knots_num=12)   # parameter basis\n",
    "# pairs = [(xB, bB)]\n",
    "\n",
    "# # Model (no penalty)\n",
    "# model = ScalarOnFunctionModel(\n",
    "#     basis_pairs=pairs,\n",
    "#     criterion=\"A\",       # or \"A\"\n",
    "#     intercept=True,\n",
    "#     lambda_penalty=None  # NO PENALTY\n",
    "# )\n",
    "\n",
    "# # NBDO setup\n",
    "# runs = 30\n",
    "# num_designs = 256\n",
    "# latent_dim = 4\n",
    "\n",
    "# opt = NBDO(model=model, latent_dim=latent_dim, seed=SEED, verbose=False)\n",
    "# opt.compute_train_set(num_designs=num_designs, runs=runs, random_state=SEED)\n",
    "\n",
    "# # Fit the autoencoder (small epochs for quick smoke)\n",
    "# opt.fit(epochs=50, batch_size=32, patience=5)\n",
    "\n",
    "# # BO in latent space (small n_calls for speed)\n",
    "# report0, design0 = opt.optimize(n_calls=10, n_random_starts=5)\n",
    "\n",
    "# print(\"=== NO PENALTY ===\")\n",
    "# print(f\"runs = {runs}, Kx = {model.Kx}, Kb = {model.Kb}, p = {model.p}\")\n",
    "# print(f\"Optimal report (criterion='A' -> trace(M)): {report0:.6g}\")\n",
    "# print(\"Design shape:\", design0.shape)\n",
    "\n",
    "# # === NO PENALTY ===\n",
    "# # runs = 30, Kx = 14, Kb = 14, p = 15\n",
    "# # Optimal report (criterion='A' -> trace(M)): 4132.03\n",
    "# # Design shape: (30, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Smoke test: Scalar-on-Function + NBDO (no penalty) ---\n",
    "# import os, numpy as np, tensorflow as tf\n",
    "\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from models.sof import ScalarOnFunctionModel\n",
    "# from optimizers.nbdo import NBDO\n",
    "\n",
    "# # Reproducibility\n",
    "# SEED = 42\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "# # Bases (1 factor for speed; feel free to add more)\n",
    "# xB = BSplineBasis(degree=3, total_knots_num=12)   # input basis\n",
    "# bB = BSplineBasis(degree=3, total_knots_num=12)   # parameter basis\n",
    "# pairs = [(xB, bB)]\n",
    "\n",
    "# # Model (no penalty)\n",
    "# model = ScalarOnFunctionModel(\n",
    "#     basis_pairs=pairs,\n",
    "#     criterion=\"A\",       # or \"A\"\n",
    "#     intercept=True,\n",
    "#     lambda_penalty=0.1  # NO PENALTY\n",
    "# )\n",
    "\n",
    "# # NBDO setup\n",
    "# runs = 30\n",
    "# num_designs = 256\n",
    "# latent_dim = 4\n",
    "\n",
    "# opt = NBDO(model=model, latent_dim=latent_dim, seed=SEED, verbose=False)\n",
    "# opt.compute_train_set(num_designs=num_designs, runs=runs, random_state=SEED)\n",
    "\n",
    "# # Fit the autoencoder (small epochs for quick smoke)\n",
    "# opt.fit(epochs=50, batch_size=32, patience=5)\n",
    "\n",
    "# # BO in latent space (small n_calls for speed)\n",
    "# report0, design0 = opt.optimize(n_calls=10, n_random_starts=5)\n",
    "\n",
    "# print(\"=== NO PENALTY ===\")\n",
    "# print(f\"runs = {runs}, Kx = {model.Kx}, Kb = {model.Kb}, p = {model.p}\")\n",
    "# print(f\"Optimal report (criterion='A' -> trace(M)): {report0:.6g}\")\n",
    "# print(\"Design shape:\", design0.shape)\n",
    "\n",
    "# # === NO PENALTY ===\n",
    "# # runs = 30, Kx = 14, Kb = 14, p = 15\n",
    "# # Optimal report (criterion='A' -> trace(M)): 3.44801\n",
    "# # Design shape: (30, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np, tensorflow as tf\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from bases.polynomial import PolynomialBasis\n",
    "# from bases.fourier import FourierBasis\n",
    "# from models.fof import FunctionOnFunctionModel\n",
    "\n",
    "# # Predictor bases (η over s)\n",
    "# xB = BSplineBasis(degree=3, total_knots_num=12)   # c(s)\n",
    "# bB = PolynomialBasis(degree=3)                    # η(s)  (Kb=4)\n",
    "# pairs = [(xB, bB)]\n",
    "\n",
    "# # Response basis θ(t)\n",
    "# theta = FourierBasis(n_harmonics=3, include_constant=True)  # L = 1 + 2*3 = 7\n",
    "\n",
    "# m = FunctionOnFunctionModel(\n",
    "#     basis_pairs=pairs,\n",
    "#     criterion=\"A\",\n",
    "#     intercept=True,\n",
    "#     response_basis=theta,\n",
    "#     lambda_s=0.5,            # activate R_s\n",
    "#     lambda_t=0.25,           # activate S_t & J_HH\n",
    "# )\n",
    "\n",
    "# print(\"Kb =\", m.Kb, \"p =\", m.p, \"L =\", theta.num_basis())\n",
    "# print(\"R_s is None?\", m.R_s is None, \"shape:\", None if m.R_s is None else m.R_s.shape)\n",
    "# print(\"S_t is None?\", m.S_t is None, \"shape:\", None if m.S_t is None else m.S_t.shape)\n",
    "# print(\"J_HH is None?\", m.J_HH is None, \"shape:\", None if m.J_HH is None else m.J_HH.shape)\n",
    "\n",
    "# # PSD-ish sanity:\n",
    "# def min_eig(a): \n",
    "#     w = np.linalg.eigvalsh(((a+a.T)/2.0))\n",
    "#     return float(w.min())\n",
    "\n",
    "# if m.R_s is not None:\n",
    "#     R0 = m.R_s.numpy()[1:,1:]  # drop intercept row/col\n",
    "#     print(\"min eig R_s (no intercept):\", f\"{min_eig(R0):.3e}\")\n",
    "# if m.S_t is not None:\n",
    "#     print(\"min eig S_t:\", f\"{min_eig(m.S_t.numpy()):.3e}\")\n",
    "# if m.J_HH is not None:\n",
    "#     J0 = m.J_HH.numpy()\n",
    "#     print(\"J_HH[0,0] (should be 1):\", J0[0,0])\n",
    "#     print(\"min eig J_HH:\", f\"{min_eig(J0):.3e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np, tensorflow as tf\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from bases.polynomial import PolynomialBasis\n",
    "# from bases.fourier import FourierBasis\n",
    "# from models.fof import FunctionOnFunctionModel\n",
    "\n",
    "# # One predictor\n",
    "# xB = BSplineBasis(3, 10)       # c(s)\n",
    "# eta = PolynomialBasis(3)       # η(s), Kb=4\n",
    "# pairs = [(xB, eta)]\n",
    "# theta = FourierBasis(2, True)  # L = 1 + 2*2 = 5\n",
    "\n",
    "# # Same design Γ for all evaluations\n",
    "# m_base = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=True, response_basis=theta)\n",
    "# runs = 8\n",
    "# Gamma = np.random.uniform(-1,1,(runs, m_base.Kx)).astype(np.float64)\n",
    "\n",
    "# # No penalty\n",
    "# loss0 = float(m_base.objective(Gamma))\n",
    "\n",
    "# # s-penalty only\n",
    "# m_s = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=True,\n",
    "#                               response_basis=theta, lambda_s=0.5, lambda_t=None)\n",
    "# loss_s = float(m_s.objective(Gamma))\n",
    "\n",
    "# # t-penalty only\n",
    "# m_t = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=True,\n",
    "#                               response_basis=theta, lambda_s=None, lambda_t=0.5)\n",
    "# loss_t = float(m_t.objective(Gamma))\n",
    "\n",
    "# # both penalties\n",
    "# m_both = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=True,\n",
    "#                                  response_basis=theta, lambda_s=0.5, lambda_t=0.5)\n",
    "# loss_b = float(m_both.objective(Gamma))\n",
    "\n",
    "# print(\"A-loss (no pen)   :\", loss0)\n",
    "# print(\"A-loss (s pen)    :\", loss_s, \"  <= no pen ? \", loss_s <= loss0)\n",
    "# print(\"A-loss (t pen)    :\", loss_t, \"  <= no pen ? \", loss_t <= loss0)\n",
    "# print(\"A-loss (both)     :\", loss_b, \"  <= each  ? \", loss_b <= min(loss_s, loss_t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np, tensorflow as tf\n",
    "\n",
    "# # Assume you've already built:\n",
    "# # m_base  = FoF with lambda_s=None, lambda_t=None, response_basis=theta\n",
    "# # m_t     = FoF with lambda_s=None, lambda_t>0, response_basis=theta\n",
    "# # Gamma   = some fixed design (runs, m_base.Kx)\n",
    "# L = m_t.response_basis.num_basis()\n",
    "\n",
    "# # 1) No-pen A-loss on p×p\n",
    "# loss0 = float(m_base.objective(Gamma))\n",
    "\n",
    "# # 2) Lifted baseline A-loss on (L*p)×(L*p): F0 = I_L ⊗ Mz\n",
    "# Z = m_base.model_matrix(Gamma)\n",
    "# Mz = m_base.information_matrix(Z)                         # (p,p)\n",
    "# F0 = tf.linalg.LinearOperatorBlockDiag(\n",
    "#         [tf.linalg.LinearOperatorFullMatrix(Mz)] * L\n",
    "#      ).to_dense()                                         # (L*p, L*p)\n",
    "# loss_F0 = float(m_base.psi.loss_from_M(F0).numpy())\n",
    "\n",
    "# # 3) t-penalized A-loss (already on (L*p)×(L*p))\n",
    "# loss_t = float(m_t.objective(Gamma))\n",
    "\n",
    "# print(\"A-loss no-pen (p×p):\", loss0)\n",
    "# print(\"Lifted baseline (I⊗M):\", loss_F0, \" ~ L*loss0 =\", L*loss0)\n",
    "# print(\"t-pen A-loss:\", loss_t, \" <= lifted baseline ? \", loss_t <= loss_F0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=True,\n",
    "#                               response_basis=theta, lambda_s=0.1, lambda_t=0.5)\n",
    "# # Assuming 'm' is a FunctionOnFunctionModel with intercept=True\n",
    "# if m.R_s is not None:\n",
    "#     R = m.R_s.numpy()\n",
    "#     print(\"R_s[0,0] =\", R[0,0], \" (expect 0)\")\n",
    "#     print(\"any intercept row/col nonzero? \", np.any(np.abs(R[0,:])>1e-12) or np.any(np.abs(R[:,0])>1e-12))\n",
    "\n",
    "# if m.J_HH is not None:\n",
    "#     JH = m.J_HH.numpy()\n",
    "#     print(\"J_HH[0,0] =\", JH[0,0], \" (expect 1)\")\n",
    "#     print(\"any off-diag in intercept row/col? \", np.any(np.abs(JH[0,1:])>1e-12) or np.any(np.abs(JH[1:,0])>1e-12))\n",
    "\n",
    "# if m.S_t is not None and getattr(m, \"response_basis\", None):\n",
    "#     # If the response basis includes a constant, its roughness row/col should be ~0\n",
    "#     # We assume the constant is basis index 0 for Fourier/Polynomial.\n",
    "#     St = m.S_t.numpy()\n",
    "#     print(\"S_t row/col 0 near zero? \",\n",
    "#           np.all(np.abs(St[0,:])<1e-8) and np.all(np.abs(St[:,0])<1e-8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np, tensorflow as tf\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from bases.polynomial import PolynomialBasis\n",
    "# from bases.fourier import FourierBasis\n",
    "# from models.fof import FunctionOnFunctionModel\n",
    "\n",
    "# # Two factors with different parameter bases\n",
    "# x1, eta1 = BSplineBasis(3,12), PolynomialBasis(3)         # Kb1=4\n",
    "# x2, eta2 = BSplineBasis(3,10), FourierBasis(2, True)      # Kb2=1+2*2=5\n",
    "# pairs = [(x1, eta1), (x2, eta2)]\n",
    "# theta = FourierBasis(2, True)  # L=5\n",
    "\n",
    "# m = FunctionOnFunctionModel(\n",
    "#     basis_pairs=pairs,\n",
    "#     criterion=\"A\",\n",
    "#     intercept=True,\n",
    "#     response_basis=theta,\n",
    "#     lambda_s=0.3,\n",
    "#     lambda_t=0.2,\n",
    "# )\n",
    "\n",
    "# print(\"Kb total:\", m.Kb, \" (expect 4+5=9)\")\n",
    "# print(\"p:\", m.p, \" (Kb+1 because intercept)\")\n",
    "# print(\"Shapes → R_s:\", None if m.R_s is None else m.R_s.shape,\n",
    "#       \" J_HH:\", None if m.J_HH is None else m.J_HH.shape,\n",
    "#       \" S_t:\", None if m.S_t is None else m.S_t.shape)\n",
    "\n",
    "# # Verify block structure (drop intercept row/col)\n",
    "# R0 = m.R_s.numpy()[1:,1:]\n",
    "# J0 = m.J_HH.numpy()[1:,1:]\n",
    "# Kb1, Kb2 = eta1.num_basis(), eta2.num_basis()\n",
    "# R_off = R0[:Kb1, Kb1:]\n",
    "# J_off = J0[:Kb1, Kb1:]\n",
    "\n",
    "# print(\"‖R_s off-block‖ (≈0):\", np.linalg.norm(R_off))\n",
    "# print(\"‖J_HH off-block‖ (≈0):\", np.linalg.norm(J_off))\n",
    "\n",
    "# # Dimension of penalized info F_λ: (L*p) x (L*p)\n",
    "# runs = 6\n",
    "# Gamma = np.random.uniform(-1,1,(runs, m.Kx)).astype(np.float64)\n",
    "# Mz = m.information_matrix(m.model_matrix(Gamma))\n",
    "# Fλ = m._regularize_information(Mz)\n",
    "# print(\"F_λ shape:\", Fλ.shape, \" (expect\", theta.num_basis()*m.p, \"by same)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from models.fof import FunctionOnFunctionModel\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from bases.fourier import FourierBasis\n",
    "# xB = BSplineBasis(3,12); bB = BSplineBasis(3,12); theta = FourierBasis(2, True)\n",
    "\n",
    "# # No penalty: identical behavior\n",
    "# m0 = FunctionOnFunctionModel([(xB,bB)], response_basis=None, lambda_s=None, lambda_t=None)\n",
    "# print(m0.R_s, m0.S_t, m0.J_HH)  # -> None None None\n",
    "\n",
    "# # t-penalty without response_basis should fail fast\n",
    "# try:\n",
    "#     FunctionOnFunctionModel([(xB,bB)], lambda_t=0.1)\n",
    "# except Exception as e:\n",
    "#     print(\"Expected error:\", type(e).__name__, str(e)[:60], \"...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item 11 — Sanity checks (A-loss monotonicity with s- and t- penalties)\n",
    "\n",
    "import numpy as np, tensorflow as tf\n",
    "\n",
    "from bases.bspline import BSplineBasis\n",
    "from bases.polynomial import PolynomialBasis\n",
    "from bases.fourier import FourierBasis\n",
    "from models.fof import FunctionOnFunctionModel\n",
    "\n",
    "# Bases\n",
    "xB   = BSplineBasis(3, 12)          # c(s)\n",
    "eta  = PolynomialBasis(3)           # η(s), Kb=4\n",
    "theta = FourierBasis(2, True)       # θ(t), L = 1 + 2*2 = 5\n",
    "\n",
    "pairs = [(xB, eta)]\n",
    "\n",
    "# Fixed design Γ for apples-to-apples comparisons\n",
    "rng = np.random.default_rng(123)\n",
    "runs = 10\n",
    "# Kx = xB.num_basis() here; if multiple factors, use m.Kx after init\n",
    "Kx = xB.num_basis()\n",
    "Gamma = rng.uniform(-1, 1, size=(runs, Kx)).astype(np.float64)\n",
    "\n",
    "# Models: base, s-pen, t-pen, both\n",
    "m_base = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=True, response_basis=theta)\n",
    "m_s    = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=True, response_basis=theta, lambda_s=0.3)\n",
    "m_t    = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=True, response_basis=theta, lambda_t=0.3)\n",
    "m_both = FunctionOnFunctionModel(pairs, criterion=\"A\", intercept=True, response_basis=theta, lambda_s=0.3, lambda_t=0.3)\n",
    "\n",
    "# A-loss values on the SAME Γ\n",
    "loss0 = float(m_base.objective(Gamma))      # tr(Mz^{-1}) on p×p\n",
    "loss_s = float(m_s.objective(Gamma))        # tr((Mz+λs Rs)^{-1})\n",
    "loss_t = float(m_t.objective(Gamma))        # tr(Fλ^{-1}) on (L*p)×(L*p)\n",
    "loss_b = float(m_both.objective(Gamma))     # tr(Fλ^{-1}) with both penalties\n",
    "\n",
    "# Lifted baseline for t-pen: F0 = I_L ⊗ Mz\n",
    "Z  = m_base.model_matrix(Gamma)\n",
    "Mz = m_base.information_matrix(Z)  # (p,p)\n",
    "L  = theta.num_basis()\n",
    "F0 = tf.linalg.LinearOperatorBlockDiag(\n",
    "        [tf.linalg.LinearOperatorFullMatrix(Mz)] * L\n",
    "     ).to_dense()\n",
    "loss_F0 = float(m_base.psi.loss_from_M(F0).numpy())   # should be ~ L * loss0\n",
    "\n",
    "print(\"A-loss no-pen (p×p):            \", loss0)\n",
    "print(\"Lifted baseline (I⊗Mz):         \", loss_F0, \"  ~ L*loss0 =\", L*loss0)\n",
    "print(\"A-loss s-pen <= no-pen?         \", loss_s, \" <= \", loss0, \" -> \", loss_s <= loss0)\n",
    "print(\"A-loss t-pen <= lifted baseline?\", loss_t, \" <= \", loss_F0, \" -> \", loss_t <= loss_F0)\n",
    "print(\"A-loss both <= min(s, t scaled)?\", loss_b, \" <= \", min(loss_s, loss_t), \" -> \", loss_b <= min(loss_s, loss_t))\n",
    "\n",
    "# (Optional) dimension-invariant view: normalize t-pen/both by L and compare to no-pen\n",
    "print(\"Scaled t-pen  <= no-pen?        \", (loss_t / L) <= loss0)\n",
    "print(\"Scaled both   <= no-pen?        \", (loss_b / L) <= loss0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Item 11 — Structure: block-diagonal R_s/J_HH, intercept padding, analytic poly R check\n",
    "\n",
    "# import numpy as np\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from bases.polynomial import PolynomialBasis\n",
    "# from bases.fourier import FourierBasis\n",
    "# from models.fof import FunctionOnFunctionModel\n",
    "\n",
    "# # --- A) Multi-factor structure (different Kb per factor) ---\n",
    "# x1, eta1 = BSplineBasis(3, 12), PolynomialBasis(3)        # Kb1 = 4\n",
    "# x2, eta2 = BSplineBasis(3, 10), FourierBasis(2, True)     # Kb2 = 1 + 2*2 = 5\n",
    "# pairs = [(x1, eta1), (x2, eta2)]\n",
    "# theta = FourierBasis(2, True)  # L=5\n",
    "\n",
    "# m = FunctionOnFunctionModel(\n",
    "#     basis_pairs=pairs, criterion=\"A\", intercept=True,\n",
    "#     response_basis=theta, lambda_s=0.2, lambda_t=0.2\n",
    "# )\n",
    "\n",
    "# print(\"Kb total:\", m.Kb, \" (expect 4+5=9)\")\n",
    "# print(\"p:\", m.p, \" (Kb+1 if intercept)\")\n",
    "# print(\"Shapes: R_s\", None if m.R_s is None else m.R_s.shape,\n",
    "#       \"J_HH\", None if m.J_HH is None else m.J_HH.shape,\n",
    "#       \"S_t\", None if m.S_t is None else m.S_t.shape)\n",
    "\n",
    "# # Drop intercept to inspect blocks\n",
    "# R0 = m.R_s.numpy()[1:, 1:]\n",
    "# J0 = m.J_HH.numpy()[1:, 1:]\n",
    "# Kb1, Kb2 = eta1.num_basis(), eta2.num_basis()\n",
    "# R_off = R0[:Kb1, Kb1:]\n",
    "# J_off = J0[:Kb1, Kb1:]\n",
    "# print(\"‖R_s off-block‖ (≈0):\", np.linalg.norm(R_off))\n",
    "# print(\"‖J_HH off-block‖ (≈0):\", np.linalg.norm(J_off))\n",
    "\n",
    "# # Intercept padding checks\n",
    "# print(\"R_s[0,0] (expect 0):\", float(m.R_s.numpy()[0,0]))\n",
    "# print(\"J_HH[0,0] (expect 1):\", float(m.J_HH.numpy()[0,0]))\n",
    "\n",
    "# # Response penalty: constant row/col ~ 0 if basis includes constant\n",
    "# St = m.S_t.numpy()\n",
    "# print(\"S_t first row/col near 0?\", np.all(np.abs(St[0,:]) < 1e-8) and np.all(np.abs(St[:,0]) < 1e-8))\n",
    "\n",
    "# # --- B) Analytic polynomial R check for degree=3 ---\n",
    "# eta_poly = PolynomialBasis(3)  # {1, t, t^2, t^3}\n",
    "# xB      = BSplineBasis(3, 10)  # arbitrary c(s)\n",
    "# m_poly  = FunctionOnFunctionModel(\n",
    "#     basis_pairs=[(xB, eta_poly)], criterion=\"A\", intercept=True,\n",
    "#     response_basis=theta, lambda_s=0.1, lambda_t=None\n",
    "# )\n",
    "# # Extract the (Kb x Kb) block (drop intercept row/col)\n",
    "# Rpoly = m_poly.R_s.numpy()[1:, 1:]\n",
    "# # Analytic expectation for degree 3 monomials: bottom-right 2x2 = [[4,6],[6,12]]\n",
    "# R_expected = np.zeros((4,4))\n",
    "# R_expected[2,2] = 4.0; R_expected[2,3] = 6.0\n",
    "# R_expected[3,2] = 6.0; R_expected[3,3] = 12.0\n",
    "\n",
    "# print(\"Polynomial R (numeric):\\n\", np.round(Rpoly, 5))\n",
    "# print(\"Polynomial R (analytic):\\n\", R_expected)\n",
    "# print(\"Max |diff|:\", float(np.max(np.abs(Rpoly - R_expected))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Smoke test: Function-on-Function + NBDO (NO penalty) ---\n",
    "# import os, numpy as np, tensorflow as tf\n",
    "\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from bases.fourier import FourierBasis\n",
    "# from models.fof import FunctionOnFunctionModel\n",
    "# from optimizers.nbdo import NBDO\n",
    "\n",
    "# # Reproducibility\n",
    "# SEED = 123\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "# # Bases\n",
    "# xB    = BSplineBasis(degree=3, total_knots_num=12)   # c(s)\n",
    "# eta   = BSplineBasis(degree=3, total_knots_num=12)   # η(s)\n",
    "# theta = FourierBasis(n_harmonics=2, include_constant=True)  # θ(t), L = 5\n",
    "\n",
    "# pairs = [(xB, eta)]\n",
    "\n",
    "# # Model (no penalties)\n",
    "# model = FunctionOnFunctionModel(\n",
    "#     basis_pairs=pairs,\n",
    "#     criterion=\"A\",\n",
    "#     intercept=True,\n",
    "#     response_basis=theta,   # harmless even if no t-penalty\n",
    "#     lambda_s=None,\n",
    "#     lambda_t=None,\n",
    "# )\n",
    "\n",
    "# # NBDO\n",
    "# runs = 10\n",
    "# num_designs = 256\n",
    "# latent_dim = 4\n",
    "\n",
    "# opt = NBDO(model=model, latent_dim=latent_dim, seed=SEED, verbose=False)\n",
    "# opt.compute_train_set(num_designs=num_designs, runs=runs, random_state=SEED)\n",
    "# opt.fit(epochs=50, batch_size=32, patience=5)\n",
    "# report0, design0 = opt.optimize(n_calls=10, n_random_starts=5)\n",
    "\n",
    "# print(\"=== FoF: NO PENALTY ===\")\n",
    "# print(f\"runs={runs}, Kx={model.Kx}, Kb={model.Kb}, p={model.p}, effective_p={model.effective_p}\")\n",
    "# print(f\"A-report (trace(M^-1)) = {report0:.6g}\")\n",
    "# print(\"Design shape:\", design0.shape)\n",
    "\n",
    "# # === FoF: NO PENALTY ===\n",
    "# # runs=10, Kx=14, Kb=14, p=15, effective_p=15\n",
    "# # A-report (trace(M^-1)) = 5.00056e+06\n",
    "# # Design shape: (10, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # --- Smoke test: Function-on-Function + NBDO (s-penalty only) ---\n",
    "# import os, numpy as np, tensorflow as tf\n",
    "\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from bases.fourier import FourierBasis\n",
    "# from models.fof import FunctionOnFunctionModel\n",
    "# from optimizers.nbdo import NBDO\n",
    "\n",
    "# SEED = 123\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "# # Same bases as Cell 1\n",
    "# xB    = BSplineBasis(degree=3, total_knots_num=12)   # c(s)\n",
    "# eta   = BSplineBasis(degree=3, total_knots_num=12)   # η(s)\n",
    "# theta = FourierBasis(n_harmonics=2, include_constant=True)  # θ(t), L = 5\n",
    "# pairs = [(xB, eta)]\n",
    "\n",
    "# # Model (s-penalty active)\n",
    "# model = FunctionOnFunctionModel(\n",
    "#     basis_pairs=pairs,\n",
    "#     criterion=\"A\",\n",
    "#     intercept=True,\n",
    "#     response_basis=theta,     # kept for consistency\n",
    "#     lambda_s=0.1,             # s-direction roughness\n",
    "#     lambda_t=None,            # no t-penalty\n",
    "# )\n",
    "\n",
    "# # NBDO (same settings)\n",
    "# runs = 10\n",
    "# num_designs = 256\n",
    "# latent_dim = 4\n",
    "\n",
    "# opt = NBDO(model=model, latent_dim=latent_dim, seed=SEED, verbose=False)\n",
    "# opt.compute_train_set(num_designs=num_designs, runs=runs, random_state=SEED)\n",
    "# opt.fit(epochs=50, batch_size=32, patience=5)\n",
    "# report_s, design_s = opt.optimize(n_calls=10, n_random_starts=5)\n",
    "\n",
    "# print(\"=== FoF: s-PENALTY (λ_s=0.1) ===\")\n",
    "# print(f\"runs={runs}, Kx={model.Kx}, Kb={model.Kb}, p={model.p}, effective_p={model.effective_p}\")\n",
    "# print(f\"A-report (trace(M^-1)) = {report_s:.6g}\")\n",
    "# print(\"Design shape:\", design_s.shape)\n",
    "\n",
    "# # === FoF: s-PENALTY (λ_s=0.1) ===\n",
    "# # runs=10, Kx=14, Kb=14, p=15, effective_p=75\n",
    "# # A-report (trace(M^-1)) = 46.7743\n",
    "# # Design shape: (10, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FoF: BOTH PENALTIES (λ_s=0.1, λ_t=0.1) ===\n",
      "runs=10, Kx=14, Kb=14, p=15, effective_p=75\n",
      "A-report (trace(M^-1)) = 10.8715\n",
      "Design shape: (10, 14)\n"
     ]
    }
   ],
   "source": [
    "# # --- Smoke test: Function-on-Function + NBDO (both s & t penalties) ---\n",
    "# import os, numpy as np, tensorflow as tf\n",
    "\n",
    "# from bases.bspline import BSplineBasis\n",
    "# from bases.fourier import FourierBasis\n",
    "# from models.fof import FunctionOnFunctionModel\n",
    "# from optimizers.nbdo import NBDO\n",
    "\n",
    "# SEED = 123\n",
    "# np.random.seed(SEED)\n",
    "# tf.random.set_seed(SEED)\n",
    "# tf.keras.utils.set_random_seed(SEED)\n",
    "\n",
    "# # Same bases\n",
    "# xB    = BSplineBasis(degree=3, total_knots_num=12)   # c(s)\n",
    "# eta   = BSplineBasis(degree=3, total_knots_num=12)   # η(s)\n",
    "# theta = FourierBasis(n_harmonics=2, include_constant=True)  # θ(t), L = 5\n",
    "# pairs = [(xB, eta)]\n",
    "\n",
    "# # Model (both penalties active)\n",
    "# model = FunctionOnFunctionModel(\n",
    "#     basis_pairs=pairs,\n",
    "#     criterion=\"A\",\n",
    "#     intercept=True,\n",
    "#     response_basis=theta,\n",
    "#     lambda_s=0.1,   # s-direction\n",
    "#     lambda_t=0.1,   # t-direction\n",
    "# )\n",
    "\n",
    "# # NBDO (same settings)\n",
    "# runs = 10\n",
    "# num_designs = 256\n",
    "# latent_dim = 4\n",
    "\n",
    "# opt = NBDO(model=model, latent_dim=latent_dim, seed=SEED, verbose=False)\n",
    "# opt.compute_train_set(num_designs=num_designs, runs=runs, random_state=SEED)\n",
    "# opt.fit(epochs=50, batch_size=32, patience=5)\n",
    "# report_b, design_b = opt.optimize(n_calls=10, n_random_starts=5)\n",
    "\n",
    "# print(\"=== FoF: BOTH PENALTIES (λ_s=0.1, λ_t=0.1) ===\")\n",
    "# print(f\"runs={runs}, Kx={model.Kx}, Kb={model.Kb}, p={model.p}, effective_p={model.effective_p}\")\n",
    "# print(f\"A-report (trace(M^-1)) = {report_b:.6g}\")\n",
    "# print(\"Design shape:\", design_b.shape)\n",
    "\n",
    "# # === FoF: BOTH PENALTIES (λ_s=0.1, λ_t=0.1) ===\n",
    "# # runs=10, Kx=14, Kb=14, p=15, effective_p=75\n",
    "# # A-report (trace(M^-1)) = 10.8715\n",
    "# # Design shape: (10, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
